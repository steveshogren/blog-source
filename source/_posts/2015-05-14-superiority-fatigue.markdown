---
layout: post
title: "Superiority Fatigue"
date: 2015-05-14 19:13
comments: true
categories: 
---

I love programming languages. I love thinking about how and why they work the
way they do. Nothing excites me like finding a new way to squeeze out a little
more productivity or safety from a language. But from my very first interaction with
other team-members, I encountered an opposite type of programmer that surprises
me to this day: the Language Luddite.

### Language Luddites

Language Luddites know one or two languages well, and are certain "their" language is
the best. They may have dabbled in a few others, but will not have learned
enough to accurately compare and contrast the merits of each. Their complaints
against other languages will either be superficial (I hate s-expressions), or
rooted firmly in ignorance (you can't build serious/fast/safe/enterprise systems
in _P_)

### Argument of Self-Knowing

A Language Luddite will defend "their" language as the most superior choice,
regardless of any evidence to the contrary. They will also refuse to learn anything
new, falling for the fallacy of "argument of self-knowing":

    If _P_ were true then I would know it; in fact I do not know it; therefore
    _P_ cannot be true.

Or, read for developers:

    If _P_ were a superior tool then I or my heroes would know it; in fact we do
    not know it; therefore _P_ cannot be superior.

Or, even more commonly:

    If _P_ were a superior tool then I or my heroes would know it; in fact I do
    not know it, and my heroes can't always be right; therefore _P_ cannot be
    superior.

Countless words have been spilled over superior technologies that exist, and
likewise countless words over the wisdom of holding fast to an existing
technology.

### Argument From Ignorance

The argument from ignorance is another common developer fallacy:

    There is no evidence for _P_. Therefore, not-_P_.

For developers

    I have not seen proof you can build serious/fast/safe/enterprise systems in
    _P_. Therefore, it cannot be done.

In the many times I have seen discussions proposed around the adoption of new
technologies or frameworks, they are almost always met with the Language
Adoption Paradox. The Language Adoption Paradox is as follows: "We cannot
consider adopting _P_ unless you prove its value. We will not spend any effort
learning _P_ to disprove its value; the burden of proof is on you. We also
cannot risk allowing you to attempt to prove the value of _P_ for adoption,
because it is unproven." Thus stonewalling any discussion or assessment
entirely.

I have decided that forcing the Language Adoption Paradox on another is
completely selfish. It dresses up fear and ignorance under the banner of
practicality. It incorrectly assumes the worst about people: they are too stupid
to learn new things quickly, new hires will be difficult, training is
impossible. It also incorrectly assumes the best about people: that they are
"good enough" to not need better tools or they are already using the best
tools.

I much prefer the mindset that tools are just tools, and can be assessed
separate from the ego of those adopting them. I believe that better tools exist
than what I am using right now, and that in every situation there exist tools
that I could adopt immediately that would allow me to produce more value than I
currently do. Philosophically, this assumes the best about people in a way I
think is more accurate: humans are extremely quick learners capable of
comprehending new concepts rapidly, hiring for a better tool will open access to
a smaller pool of more skilled developers who prefer to be as productive as
possible, and training is easy. I also assume the worst about people when it
comes to things humans are bad at: getting lots of small details repeatedly
correct.

Looking at the advancements in language design over the last thirty years shows
a distinct trend that reducing complexity by allowing the machine to take on the
management of details allows much more productivity. Simply observing the
history of languages should tell the observer that we are not done yet. There is
more that that machine can do for us, freeing our minds to focus on better
interactions, better abstractions, and better software.
